"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=Tmin),position="jitter", data=freezes) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
write.csv(freezes, "~/Documents/git/regionalrisk/analyses/output/climate_betula.csv", row.names=FALSE, eol="\r\n")
df<-read.csv("bbch_region.csv", header=TRUE)
all<-full_join(d, df)
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
View(all)
d<-read.csv("bbch_region_betula.csv", header=TRUE)
df<-read.csv("bbch_region.csv", header=TRUE)
all<-cbind(d, df)
View(d)
all<-rbind(d, df)
View(all)
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(Interpol.T)
library(chillR)
library(ggmap)
library(maps)
library(mapdata)
library(mapproj)
library(grid)
library(rworldmap)
library(gridExtra)
# Set Working Directory
setwd("~/Documents/git/regionalrisk/analyses/output")
d<-read.csv("bbch_region_betula.csv", header=TRUE)
df<-read.csv("bbch_region.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-rbind(d, df)
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
################## CLIMATE DATA?! ##############################
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(Interpol.T)
library(chillR)
library(ggmap)
library(maps)
library(mapdata)
library(mapproj)
library(grid)
library(rworldmap)
library(gridExtra)
# Set Working Directory
setwd("~/Documents/git/regionalrisk/analyses/output")
d<-read.csv("bbch_region_betula.csv", header=TRUE)
df<-read.csv("bbch_region.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-rbind(d, df)
all<-all%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
################## CLIMATE DATA?! ##############################
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
View(all)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(Interpol.T)
library(chillR)
library(ggmap)
library(maps)
library(mapdata)
library(mapproj)
library(grid)
library(rworldmap)
library(gridExtra)
# Set Working Directory
setwd("~/Documents/git/regionalrisk/analyses/output")
d<-read.csv("bbch_region_betula.csv", header=TRUE)
#df<-read.csv("bbch_region.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
################## CLIMATE DATA?! ##############################
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(Interpol.T)
library(chillR)
library(ggmap)
library(maps)
library(mapdata)
library(mapproj)
library(grid)
library(rworldmap)
library(gridExtra)
setwd("~/Documents/git/regionalrisk/analyses/output")
d<-read.csv("bbch_region_betula.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
d<-read.csv("bbch_region.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
d<-read.csv("bbch_region_betula.csv", header=TRUE)
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-strptime(x, format="%Y %j")
View(all)
d<-read.csv("bbch_region_betula.csv", header=TRUE)
eur.tempmn <- nc_open(file.path("~/Documents/git/regionalrisk/analyses/input/tn_0.25deg_reg_v15.0.nc"))
all<-d%>%filter(YEAR>=1950)
x<-paste(all$YEAR, all$DAY)
all$date<-as.Date(strptime(x, format="%Y %j"))
tempval <- list()
for(i in 1:nrow(all)){ # i = 1
# find this location
lo <- all[i,"LON"]
la <- all[i,"LAT"]
ndiff.long.cell <- abs(eur.tempmn$dim$longitude$vals-as.numeric(lo))
ndiff.lat.cell <- abs(eur.tempmn$dim$latitude$vals-as.numeric(la))
nlong.cell <- which(ndiff.long.cell==min(ndiff.long.cell))[1]
nlat.cell <- which(ndiff.lat.cell==min(ndiff.lat.cell))[1]
yr <- as.numeric(all[i,"YEAR"])#
# start and end days of the climate data we need for the lat/long
stday <- strptime(paste(yr, "01-02", sep="-"),"%Y-%m-%d", tz="GMT")#start day
# using fieldsample.date2, which is the same as fieldsampledate, but formatted as  "%Y-%m-%d"
#field sample date2 is the end day for chilling calculations
endday <- strptime(all[i,"date"],"%Y-%m-%d", tz = "GMT")
st <- as.numeric(as.character(stday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
en <- as.numeric(as.character(endday - strptime("1950-01-01", "%Y-%m-%d", tz = "GMT")))
if(en<st){en=st}
if(endday<stday){endday=stday}
# get temperature values for this date range.
# check the dim of the netcdf file, str(netcdf), and see what the order of the different dimensions are. In this case, it goes long, lat, time. So when we are moving through the file, we give it the long and lat and date of start, then move through the files by going 'up' the cube of data to the end date
mins <- ncvar_get(eur.tempmn, 'tn',
start=c(nlong.cell,nlat.cell,st),
count=c(1, 1,en-st+1) )# this is where we move through the 'cube' to get the one vector of Temp mins
tempval[[as.character(all[i,"date"])]] <- data.frame(Lat = la,Long = lo, Date = seq(stday, endday, by="day"),
Tmin = mins)
}
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(arm)
setwd("~/Documents/git/regionalrisk/analyses/output")
bb<-read.csv("bbch_region_betula.csv", header=TRUE)
clim<-read.csv("climate_betula.csv", header=TRUE)
clim$date<-as.Date(paste(clim$year, clim$month, clim$day, sep="-"))
bb<-bb%>%dplyr::rename("lat" = LAT)%>%dplyr::rename("long"=LON)
x<-paste(bb$YEAR, bb$DAY)
bb$date<-as.Date(strptime(x, format="%Y %j"))
bb$year<-as.numeric(substr(bb$date, 0,4))
bb$month<-as.numeric(substr(bb$date, 6, 7))
bb$day<-as.numeric(substr(bb$date, 9,10))
bb<-bb%>%dplyr::select(-National_ID, -YEAR)
bb$lat<-round(bb$lat, digits=2)
bb$long<-round(bb$long, digits=2)
b.attempt<-bb%>%
group_by(year, PEP_ID, DAY)%>%
arrange(PEP_ID) %>%
filter(row_number()==1 | row_number()==n())
clim$lat<-round(clim$lat, digits=2)
clim$long<-round(clim$long, digits=2)
d<-full_join(clim, bb)
d<-filter(d, year>=1950)
View(d)
worldMap <- getMap()
# European Countries
europeanUnion <- c("Austria","Belgium","Bulgaria","Croatia","Cyprus",
"Czech Rep.","Denmark","Estonia","Finland","France",
"Germany","Greece","Hungary","Ireland","Italy","Latvia",
"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=Tmin),position="jitter", data=clim) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
View(d)
d<-filter(d, year>=1950)
how_many<-d[which(is.na(d$Tmin)),]
worldMap <- getMap()
# European Countries
europeanUnion <- c("Austria","Belgium","Bulgaria","Croatia","Cyprus",
"Czech Rep.","Denmark","Estonia","Finland","France",
"Germany","Greece","Hungary","Ireland","Italy","Latvia",
"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=Tmin),position="jitter", data=bb) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
worldMap <- getMap()
# European Countries
europeanUnion <- c("Austria","Belgium","Bulgaria","Croatia","Cyprus",
"Czech Rep.","Denmark","Estonia","Finland","France",
"Germany","Greece","Hungary","Ireland","Italy","Latvia",
"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=DAY),position="jitter", data=bb) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
worldMap <- getMap()
# European Countries
europeanUnion <- c("Austria","Belgium","Bulgaria","Croatia","Cyprus",
"Czech Rep.","Denmark","Estonia","Finland","France",
"Germany","Greece","Hungary","Ireland","Italy","Latvia",
"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=DAY),position="jitter", data=clim) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
worldMap <- getMap()
# European Countries
europeanUnion <- c("Austria","Belgium","Bulgaria","Croatia","Cyprus",
"Czech Rep.","Denmark","Estonia","Finland","France",
"Germany","Greece","Hungary","Ireland","Italy","Latvia",
"Lithuania","Luxembourg","Malta","Netherlands","Norway","Poland",
"Portugal","Romania","Slovakia","Slovenia","Spain",
"Sweden","Switzerland", "United Kingdom")
indEU <- which(worldMap$NAME%in%europeanUnion)
europeCoords <- lapply(indEU, function(i){
df <- data.frame(worldMap@polygons[[i]]@Polygons[[1]]@coords)
df$region =as.character(worldMap$NAME[i])
colnames(df) <- list("long", "lat", "region")
return(df)
})
europeCoords <- do.call("rbind", europeCoords)
eur <- ggplot(europeCoords) + geom_polygon(data = europeCoords, aes(x = long, y = lat, group=region),
color="grey", fill="white") + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
eur.map <- eur +
geom_point(aes(long, lat, color=Tmin),position="jitter", data=clim) + scale_color_gradient(low = "blue", high="red", breaks=c(30,60,90,120,150,180,210))
plot(eur.map)
