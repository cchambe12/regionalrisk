#mapWorld <- borders("world", colour="gray72", fill="gray65",ylim=c(30,70),xlim=c(-10,35)) # create a layer of borders
site<-dplyr::select(betlen.clim, lat, long, GDD, year)
site<-site[!duplicated(site),]
aes <- ggplot() +
geom_polygon(aes(x = NamMap1$long, y = NamMap1$lat, group = NamMap1$group),
color = 'gray', fill="lightgrey", size = .2) + ### This creates the base map
geom_jitter(width=3,aes(x=site[site$year==2000,]$long, y=site[site$year==2000,]$lat, color=site[site$year==2000,]$GDD), size=0.6, alpha=0.4) + theme_classic() +
theme(panel.border = element_blank(), ### extra tweaks to background and plot to make sure it doesn't have grid lines, etc.
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
axis.text = element_blank(),
plot.title=element_text(size = 10, face="bold.italic"),
legend.position = "none",
axis.title = element_blank(),
panel.background = element_rect(fill="grey95")) + ### to make sure the continent doesn't blend in with the ocea
sc +
labs(color="GDDs")
aes
for(i in 1:length(spslist)){
spps <- getspsshape(spslist,i,sps.1)
spg <- sps.1
coordinates(spg) <- ~ long + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
ras.numpixels<-rasterDF[[1]]
values(ras.numpixels)<-1:ncell(ras.numpixels)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
coords$lat.long <- paste(coords$lat, coords$long)
sps.1$lat.long <- paste(sps.1$lat, sps.1$long)
spps.clim <- sps.1[(sps.1$lat.long%in%coords$lat.long),]
namspp <- data.frame(simpspp = species.list.clean,
compspp = c("Betula_lenta", "Populus_grandidentata", "Fagus_grandifolia", "Quercus_rubra",
"Acer_pensylvanicum", "Betula_papyrifera", "Fraxinus_nigra", #"Alnus_rubra",
"Pseudotsuga_menziesii", "Prunus_pensylvanica", "Betula_alleghaniensis",
"Acer_saccharum", "Alnus_incana", "Acer_rubrum", "Corylus_cornuta", "Picea_glauca"))
write.csv(spps.clim, paste0("~/Documents/git/ospree/analyses/ranges/climoutput/Climate.in.range.",namspp$compspp[i],".1980.2016.csv"), row.names = FALSE)
}
spps <- getspsshape(spslist,i,sps.1)
spg <- sps.1
coordinates(spg) <- ~ long + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
ras.numpixels<-rasterDF[[1]]
spg <- sps.1
coordinates(spg) <- ~ long + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
ras.numpixels<-rasterDF[[1]]
values(ras.numpixels)<-1:ncell(ras.numpixels)
sps.1$lat.long <- paste(sps.1$lat, sps.1$long)
namspp <- data.frame(simpspp = species.list.clean,
compspp = c("Betula_lenta", "Populus_grandidentata", "Fagus_grandifolia", "Quercus_rubra",
"Acer_pensylvanicum", "Betula_papyrifera", "Fraxinus_nigra", #"Alnus_rubra",
"Pseudotsuga_menziesii", "Prunus_pensylvanica", "Betula_alleghaniensis",
"Acer_saccharum", "Alnus_incana", "Acer_rubrum", "Corylus_cornuta", "Picea_glauca"))
for(i in 1:length(spslist)){
spps <- getspsshape(spslist,i,sps.1)
print(i)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
coords$lat.long <- paste(coords$lat, coords$long)
spps.clim <- sps.1[(sps.1$lat.long%in%coords$lat.long),]
write.csv(spps.clim, paste0("~/Documents/git/ospree/analyses/ranges/climoutput/Climate.in.range.",namspp$compspp[i],".1980.2016.csv"), row.names = FALSE)
}
spps <- getspsshape(spslist,i,sps.1)
print(i)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
coords$lat.long <- paste(coords$lat, coords$long)
for(i in 1:length(spslist)){
spps <- getspsshape(spslist,i,sps.1)
print(i)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
names(coords) <- c("long", "lat")
coords$lat.long <- paste(coords$lat, coords$long)
spps.clim <- sps.1[(sps.1$lat.long%in%coords$lat.long),]
write.csv(spps.clim, paste0("~/Documents/git/ospree/analyses/ranges/climoutput/Climate.in.range.",namspp$compspp[i],".1980.2016.csv"), row.names = FALSE)
}
species.list.clean
spslist
spslist <- spslist[-8]
spslist
## function to extract/correct the shape for a given species
getspsshape<-function(spslist,sps.num, ras.numpixels){ #i=1
i<-sps.num #sps.num=1
spsi<-spslist[i]
path.source.i <- "~/Documents/git/ospree/analyses/ranges/NA_range_files/NA_ranges.zip"
#unzipped <- unzip("/n/wolkovich_lab/Lab/Cat/NA_range_files/NA_ranges.zip",
#                list = TRUE)$Name
unzipped <- unzip("~/Documents/git/ospree/analyses/ranges/NA_range_files/NA_ranges.zip", list = TRUE)$Name
shpsource <-"NA_ranges"
zipped_name.i <- grep(paste(shpsource, spsi, spsi, sep="/"), unzipped, ignore.case = TRUE, value = TRUE)
# load shapefile
unzip(path.source.i, files=zipped_name.i)
# load shapefile
spsshape <- shapefile(zipped_name.i[1])
## need to re-project shape from lamber equal area to geographic
#spsshapeproj <- spsshape
proj4string(spsshape) <- CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 ")
spsshapeproj<-spTransform(spsshape,CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 "))
#lines(spsshapeproj)
#
return(spsshapeproj)
}
names(sps.1)[names(sps.1) == "x"] <- "long"
names(sps.1)[names(sps.1) == "y"] <- "lat"
spg <- sps.1
coordinates(spg) <- ~ long + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
ras.numpixels<-rasterDF[[1]]
values(ras.numpixels)<-1:ncell(ras.numpixels)
sps.1$lat.long <- paste(sps.1$lat, sps.1$long)
namspp <- data.frame(simpspp = species.list.clean,
compspp = c("Betula_lenta", "Populus_grandidentata", "Fagus_grandifolia", "Quercus_rubra",
"Acer_pensylvanicum", "Betula_papyrifera", "Fraxinus_nigra", #"Alnus_rubra",
"Pseudotsuga_menziesii", "Prunus_pensylvanica", "Betula_alleghaniensis",
"Acer_saccharum", "Alnus_incana", "Acer_rubrum", "Corylus_cornuta", "Picea_glauca"))
i=2
spps <- getspsshape(spslist,i,sps.1)
print(i)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
names(coords) <- c("long", "lat")
coords$lat.long <- paste(coords$lat, coords$long)
spps.clim <- sps.1[(sps.1$lat.long%in%coords$lat.long),]
#mapWorld <- borders("world", colour="gray72", fill="gray65",ylim=c(30,70),xlim=c(-10,35)) # create a layer of borders
site<-dplyr::select(spps.clim, lat, long, GDD, year)
site<-site[!duplicated(site),]
aes <- ggplot() +
geom_polygon(aes(x = NamMap1$long, y = NamMap1$lat, group = NamMap1$group),
color = 'gray', fill="lightgrey", size = .2) + ### This creates the base map
geom_jitter(width=3,aes(x=site[site$year==2000,]$long, y=site[site$year==2000,]$lat, color=site[site$year==2000,]$GDD), size=0.6, alpha=0.4) + theme_classic() +
theme(panel.border = element_blank(), ### extra tweaks to background and plot to make sure it doesn't have grid lines, etc.
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
axis.text = element_blank(),
plot.title=element_text(size = 10, face="bold.italic"),
legend.position = "none",
axis.title = element_blank(),
panel.background = element_rect(fill="grey95")) + ### to make sure the continent doesn't blend in with the ocea
sc +
labs(color="GDDs")
aes
plot(spps)
for(i in 1:length(spslist)){ #i=2
spps <- getspsshape(spslist,i,sps.1)
print(i)
pixels.sps.i<-unique(sort(unlist(extract(ras.numpixels,spps))))
coords <- as.data.frame(coordinates(ras.numpixels)[pixels.sps.i,])
names(coords) <- c("long", "lat")
coords$lat.long <- paste(coords$lat, coords$long)
spps.clim <- sps.1[(sps.1$lat.long%in%coords$lat.long),]
write.csv(spps.clim, paste0("~/Documents/git/ospree/analyses/ranges/climoutput/Climate.in.range.",namspp$compspp[i],".1980.2016.csv"), row.names = FALSE)
}
setwd("~/Desktop")
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
# Then create a list of dataframes
n <- length(mycsv)
mylist <- vector("list", n)
mylist
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
View(mylist)
names(mylist)
mycsv
setwd("~/Desktop")
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
n <- length(mycsv)
n
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
x <- x[-c(1:9, 11:16, 28:32), ] ;
x <- x[, -1] ;
x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:9, 11:16, 28:32), ] ;
x <- x[, -1] ;
x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[, -c(1:9, 11:16, 28:32)] ;
x <- x[-1, ] ;
x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:9, 11:16, 28:32), ] ;
x <- x[, -1] ;
x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
#{x <- x[-c(1:9, 11:16, 28:32), ] ;
#x <- x[, -1] ;
x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
#{x <- x[-c(1:9, 11:16, 28:32), ] ;
#x <- x[, -1] ;
{x <- subset(x, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:9, 11:16, 28:32), ] ;
x <- x[, -1] ;
return(x)})
head(mylist[[1]])
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
return(x)})
head(mylist[[1]])
mylist[[1]][1,]
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
colnames(x) <- x[1]
return(x)})
head(mylist[[1]])
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
colnames(x) <- c(x[1])
return(x)})
head(mylist[[1]])
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ]
colnames(x2) <- x[1,]
return(x2)})
head(mylist[[1]])
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
head(mylist[[1]])
names(mylist)
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
x2$id <- names(mylist)
return(x2)})
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
x2$id <- names(x)
return(x2)})
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
head(mylist[[1]])
foo <- mylist
for(i in 1:n) foo[[i]]$id <- names(foo[[i]])
for(i in 1:n) foo[[i]]$id <- names(mycsv[[i]])
head(foo[[1]])
foo[[i]]$id
names(mycsv[[i]])
mycsv[i]
for(i in 1:n) foo[[i]]$id <- mycsv[i]
head(foo[[1]])
for(i in 1:n) mylist[[i]]$id <- mycsv[i]
head(mylist[[1]])
for(i in 1:n) foo[[i]]$tx <- grep("-01_" | "-11_", foo[[i]]$id)
for(i in 1:n) foo[[i]]$tx <- grep("[-01_]" | "[-11_]", foo[[i]]$id)
for(i in 1:n) foo[[i]]$tx <- ifelse(grepl("-01_", foo[[i]]$id), "01",
ifelse(grepl("[-11_]", foo[[i]]$id), "11", NA)
{names(x) <- c("date.time", "temp") ;
x$date<-gsub("\\s* .*$", '', x$date.time) ;
x$date<- as.Date(x$date, "%m/%d/%Y") ;
x$date<-as.Date(gsub("001", "201", x$date)) ;
x$year<-substr(x$date, 0, 4) ;
x$doy<-yday(x$date) ;
x$hour<-gsub("^.* \\s*|\\s*:.*$", '', x$date.time) ;
return(x)})
for(i in 1:n) foo[[i]]$tx <- ifelse(grepl("-01_", foo[[i]]$id), "01",
ifelse(grepl("[-11_]", foo[[i]]$id), "11", NA))
head(foo[[1]])
for(i in 1:n) mylist[[i]]$tx <- ifelse(grepl("-01_", mylist[[i]]$id), "01",
ifelse(grepl("[-11_]", mylist[[i]]$id), "11", NA))
setwd("~/Desktop")
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
## First, convert all of your .xls files to .csv
## Next, put all of your new .csv files (e.g., YP_Tomato_July052020_5-01.csv) in one folder
## In my example, I will call this folder "tomato"
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:32), ] ;
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
for(i in 1:n) mylist[[i]]$id <- mycsv[i]
for(i in 1:n) mylist[[i]]$tx <- ifelse(grepl("-01_", mylist[[i]]$id), "01",
ifelse(grepl("[-11_]", mylist[[i]]$id), "11", NA))
head(mylist[[1]])
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- rbindlist(mylist)
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind(mylist))
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind, mylist)
View(megadf)
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind, unname(mylist))
View(megadf)
setwd("~/Desktop")
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
## First, convert all of your .xls files to .csv
## Next, put all of your new .csv files (e.g., YP_Tomato_July052020_5-01.csv) in one folder
## In my example, I will call this folder "tomato"
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:16, 28:31), ] ; ### This is removing the misc rows from the Licor - double check I am not removing important rows of data for other dataframes!!
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
## Now I am adding a new column with unique ID identifier so you can split the data frames later
for(i in 1:n) mylist[[i]]$id <- mycsv[i]
## And here I am adding a column with treatment - again to split the data frames later to save accordingly
for(i in 1:n) mylist[[i]]$tx <- ifelse(grepl("-01_", mylist[[i]]$id), "01",
ifelse(grepl("[-11_]", mylist[[i]]$id), "11", NA))
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind, unname(mylist))
# Or you can open the dataframes in the environment individually:
for (i in seq(mylist))
assign(paste0("tomato", i), mylist[[i]])
View(tomato1)
View(tomato2)
setwd("~/Desktop")
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
## First, convert all of your .xls files to .csv
## Next, put all of your new .csv files (e.g., YP_Tomato_July052020_5-01.csv) in one folder
## In my example, I will call this folder "tomato"
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:15, 28:32), ] ; ### This is removing the misc rows from the Licor - double check I am not removing important rows of data for other dataframes!!
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
## Now I am adding a new column with unique ID identifier so you can split the data frames later
for(i in 1:n) mylist[[i]]$id <- mycsv[i]
## And here I am adding a column with treatment - again to split the data frames later to save accordingly
for(i in 1:n) mylist[[i]]$tx <- ifelse(grepl("-01_", mylist[[i]]$id), "01",
ifelse(grepl("[-11_]", mylist[[i]]$id), "11", NA))
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind, unname(mylist))
# Or you can open the dataframes in the environment individually:
for (i in seq(mylist)) {
assign(paste0("tomato", i), mylist[[i]])}
View(tomato1)
setwd("~/Desktop")
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
## First, convert all of your .xls files to .csv
## Next, put all of your new .csv files (e.g., YP_Tomato_July052020_5-01.csv) in one folder
## In my example, I will call this folder "tomato"
# Since they're all in the same folder now, we can load them all at once...
mycsv = as.vector(dir("tomato", pattern=".csv"))
n <- length(mycsv)
mylist <- vector("list", n)
for(i in 1:n) mylist[[i]] <- read.csv(paste0("tomato/",mycsv[i]))
names(mylist) <- mycsv
# Then we need to clean some stuff up in the data frames:
mylist <- lapply(mylist, function(x)
{x <- x[-c(1:8, 10:15, 27:31), ] ; ### This is removing the misc rows from the Licor - double check I am not removing important rows of data for other dataframes!!
x <- x[, -1] ;
x2 <- x[-1, ] ;
colnames(x2) <- x[1,] ;
x2 <- subset(x2, select=c("Photo", "Cond", "VpdL", "CO2S", "RH_R", "RH_S")) ;
return(x2)})
## Now I am adding a new column with unique ID identifier so you can split the data frames later
for(i in 1:n) mylist[[i]]$id <- mycsv[i]
## And here I am adding a column with treatment - again to split the data frames later to save accordingly
for(i in 1:n) mylist[[i]]$tx <- ifelse(grepl("-01_", mylist[[i]]$id), "01",
ifelse(grepl("[-11_]", mylist[[i]]$id), "11", NA))
## Now you can bind all rows together in the list to make a mega data frame...
megadf <- do.call(rbind, unname(mylist))
# Or you can open the dataframes in the environment individually:
for (i in seq(mylist)) {
assign(paste0("tomato", i), mylist[[i]])}
View(tomato1)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(raster)
library(reshape2)
library(data.table)
setwd("~/Documents/git/regionalrisk/analyses")
aes<-read.csv("output/bbch_region_aesculus.csv", header=TRUE)
aln<-read.csv("output/bbch_region_alnus.csv", header=TRUE)
bet<-read.csv("output/bbch_region_betula.csv", header=TRUE)
fsyl<-read.csv("output/bbch_region_fagus.csv", header=TRUE)
fra<-read.csv("output/bbch_region_fraxinus.csv", header=TRUE)
que<-read.csv("output/bbch_region_quercus.csv", header=TRUE)
head(aes)
