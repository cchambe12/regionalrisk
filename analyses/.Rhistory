trx$taxa <- ifelse(trx$taxa=="Sciurus carolinensis", "Sciurus spp.", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Sylvilagus floridanus", "Leporidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Turdus migratorius", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Carduelis tristis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Dumetella carolinensis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Quiscalus quiscula", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Zenaida macroura", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Corvus brachyrhynchos", "Corvidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Urocyon cinereoargenteus", "Vulpes vulpes and Urocyon Cinereoargentus", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Passer domesticus", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Butorides virescens", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Neovison vison", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Cardinalis cardinalis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Tamias striatus", "Rodentia", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Lontra canadensis", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Ardea herodias", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx<-subset(trx, subset=c("camera", "image", "taxa", "checkedbyhand"))
trx<-subset(trx, select=c("camera", "image", "taxa", "checkedbyhand"))
View(trx)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
## Libraries
library(dplyr)
library(ggplot2)
#Load the data
results <- read.csv("~/Desktop/test_results_usda_all.csv", header=TRUE)
classes <- read.csv("~/Desktop/listofnames.csv", header=TRUE)
results$image <- gsub(".*/\\s*|'.*", '', results$fileName)
errors <- c(4, 17)
results$modelfix<-NA
results$modelfix <- ifelse(results$guess1==22, results$guess2, results$guess1)
results$modelfix <- ifelse(results$guess1==1, results$guess2, results$modelfix)
results$modelfix <- ifelse(results$modelfix%in%errors, 18, results$modelfix)
results$camera <- gsub("_.*", '', results$image)
classes$modelfix<-classes$Class.ID
classes$group<-classes$Group.name
classes$taxa<-classes$scientific_name
results <- left_join(results, classes)
tocheck <- read.csv("~/Documents/git/cameratrap/WildlifeDetections_CameraTrap.csv", header=TRUE)
trx<-subset(tocheck, select=c("Sampling.Event", "Raw.Name", "Genus", "Species"))
trx$image <- paste(trx$Sampling.Event, trx$Raw.Name, sep="_")
trx$taxa <- paste(trx$Genus, trx$Species, sep=" ")
trx$camera <- substr(trx$image, 0, 6)
trx$camera <- ifelse(trx$camera == "ATXing", substr(trx$image, 8, 13), trx$camera)
results$camera <- ifelse(results$camera=="CAM6A", "CAM06A", results$camera)
trx$taxa <- ifelse(trx$taxa=="Vulpes vulpes", "Vulpes vulpes and Urocyon Cinereoargentus", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Canis latrans", "Canidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Sciurus carolinensis", "Sciurus spp.", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Sylvilagus floridanus", "Leporidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Turdus migratorius", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Carduelis tristis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Dumetella carolinensis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Quiscalus quiscula", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Zenaida macroura", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Corvus brachyrhynchos", "Corvidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Urocyon cinereoargenteus", "Vulpes vulpes and Urocyon Cinereoargentus", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Passer domesticus", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Butorides virescens", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Neovison vison", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Cardinalis cardinalis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Tamias striatus", "Rodentia", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Lontra canadensis", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Ardea herodias", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx<-subset(trx, select=c("camera", "image", "taxa", "checkedbyhand"))
trx<-subset(trx, select=c("camera", "image", "taxa"))
trx <- left_join(trx, classes)
trx$checkedbyhand <- trx$Class.ID
trx <- subset(trx, select=c("image", "camera","checkedbyhand"))
goo <- left_join(results, trx)
goo <- full_join(results, trx)
howmanymatch <- unique(trx$image)
howmanymatch <- unique(trx$image)
foo <- goo[(goo$image%in%howmanymatch),]
View(foo)
goo <- left_join(results, trx)
howmanymatch <- unique(trx$image)
foo <- goo[(goo$image%in%howmanymatch),]
View(goo)
709/821
(exp(-0.48)-1)*100
(exp(0.14)-1)*100
(exp(0.4)-1)*100
(exp(0.19)-1)*100
(exp(0.35)-1)*100
(exp(0.42)-1)*100
(exp(-0.83)-1)*100
load("/Users/catchamberlain/Documents/git/regionalrisk/orig_full.Rdata")
orig.full
(exp(-0.12)-1)*100
broom::tidy(orig.full)
(exp(0.0008967095)-1)*100
load("/Users/catchamberlain/Documents/git/regionalrisk/bbmod.scaled.Rdata")
load("/Users/catchamberlain/Documents/git/regionalrisk/lstfrz.scaled.Rdata")
load("/Users/catchamberlain/Documents/git/regionalrisk/tmin.simple.Rdata")
bb.mod.scaled
lstfrz.mod.scaled
tmin.simple
lstfrz <- read.csv("~/Documents/git/regionalrisk/analyses/output/lastfreezedates.csv")
lstfrz$cc <- ifelse(lstfrz$year<=1983, 0, 1)
lstfrz$cc.z <- (lstfrz$cc-mean(lstfrz$cc,na.rm=TRUE))/(2*sd(lstfrz$cc,na.rm=TRUE))
colnames(lstfrz)
load("/Users/catchamberlain/Documents/git/regionalrisk/tminmod.Rdata")
tmin.mod
171-8
163/20
163/30
163-7
156/30
### Need to first build shapefiles...
pnw_long <- c(-123,  -123,  -119, -119)
pnw_lat <- c(52, 46, 52, 46)
pnw <- cbind(pnw_lat, pnw_long)
pnw
library(sp)
pnwpoly = Polygon(pnw)
pnwps = Polygons(list(pnw),1)
pnwsps = SpatialPolygons(pnw)
plot(pnw)
plot(pnwpoly)
st_write(pnw,
"~/Documents/git/microclimates/pnw.shp", driver = "ESRI Shapefile")
proj4string(pnw) = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
require(sf)
install.packages("sf")
pnwshp<-st_as_sf(pnw)
require(sf)
pnwshp<-st_as_sf(pnw)
pnwshp<-st_as_sf(pnw, crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
coordinates(pnw)=~long+lat
### Need to first build shapefiles...
pnw_long <- c(-123,  -123,  -119, -119)
pnw_lat <- c(52, 46, 52, 46)
pnw <- cbind(pnw_lat, pnw_long)
View(pnw)
### Need to first build shapefiles...
pnw <- data.frame(long=c(-123,  -123,  -119, -119), lat= c(52, 46, 52, 46))
coordinates(pnw)=~long+lat
proj4string(pnw)<- CRS("+proj=longlat +datum=WGS84")
LLcoor<-spTransform(pnw,CRS("+proj=longlat"))
pnwshp<-spTransform(pnw,CRS("+proj=longlat"))
(78824+2337+931+655+388+94+93+60+48+45+41+41+36+34+32+23+23+19+19+16+14+10+8+7+7+5+4+4+4+3+3+3+2+2+2+2+22)
(2788+13+8+17+34+2+2+1+1)
2866/83861
osp <- read.csv("~/Documents/git/ospree/analyses/input/ospree.csv")
ospfull <- read.csv("~/Documents/git/ospree/analyses/output/ospree_clean_withchill_BB_taxon.csv")
unique(osp$datasetID)
length(unique(osp$datasetID))
range(osp$year, na.rm=TRUE)
osp <- read.csv("~/Documents/git/ospree/analyses/output/ospree2019update.csv")
osp <- read.csv("~/Documents/git/ospree/analyses/output/ospree2019update.csv")
length(unique(osp$datasetID))
range(osp$year, na.rm=TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(raster)
library(reshape2)
library(data.table)
dxx<-read.csv("~/Desktop/allspp_climateprep_midleaf.csv", header=TRUE)
dxx<-dxx[sample(nrow(dxx), 50), ]
r<-brick("~/Desktop/Big Data Files/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
bb<-dxx
bb$lat.long<-paste(bb$lat, bb$long, sep=",")
bb<-bb[!duplicated(bb$lat.long),]
lats <- bb$lat
lons <- bb$long
coords <- data.frame(x=lons,y=lats)
coords<- na.omit(coords)
points <- SpatialPoints(coords, proj4string = r@crs)
values <- extract(r,points)
dclim <- cbind.data.frame(coordinates(points),values)
dx<-reshape2::melt(dclim, id.vars=c("x","y"))
dx<-dx%>%
dplyr::rename(long=x)%>%
dplyr::rename(lat=y)%>%
dplyr::rename(date=variable)%>%
dplyr::rename(Tmin=value)
dx$date<-substr(dx$date, 2,11)
dx$Date<- gsub("[.]", "-", dx$date)
dxx<-dplyr::select(dxx, -date)
dx<-dplyr::select(dx, -date)
x<-inner_join(dx, dxx, by=c("Date", "lat", "long"))
x$fs <- 0
x$fs<- ifelse(x$Tmin<=-2.2 & x$species%in%c("FAGSYL", "FRAEXC", "QUEROB"), 1, x$fs)
x$fs<- ifelse(x$Tmin<=-5 & x$species%in%c("AESHIP", "BETPEN", "ALNRUG"), 1, x$fs)
View(x)
dxx<-read.csv("/n/wolkovich_lab/Lab/Cat/allspp_climateprep_midleaf.csv", header=TRUE)
dxx<-read.csv("~/Desktop/allspp_climateprep_midleaf.csv", header=TRUE)
View(x)
dxx<-dxx[sample(nrow(dxx), 100), ]
r<-brick("/n/wolkovich_lab/Lab/Cat/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
r<-brick("~/Desktop/Big Data Files/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
bb<-dxx
bb$lat.long<-paste(bb$lat, bb$long, sep=",")
bb<-bb[!duplicated(bb$lat.long),]
lats <- bb$lat
lons <- bb$long
coords <- data.frame(x=lons,y=lats)
coords<- na.omit(coords)
points <- SpatialPoints(coords, proj4string = r@crs)
values <- extract(r,points)
dclim <- cbind.data.frame(coordinates(points),values)
dx<-reshape2::melt(dclim, id.vars=c("x","y"))
dx<-dx%>%
dplyr::rename(long=x)%>%
dplyr::rename(lat=y)%>%
dplyr::rename(date=variable)%>%
dplyr::rename(Tmin=value)
dx$date<-substr(dx$date, 2,11)
dx$Date<- gsub("[.]", "-", dx$date)
dxx<-dplyr::select(dxx, -date)
dx<-dplyr::select(dx, -date)
x<-inner_join(dx, dxx, by=c("Date", "lat", "long"))
x$fs <- 0
x$fs<- ifelse(x$Tmin<=-2.2 & x$species%in%c("FAGSYL", "FRAEXC", "QUEROB"), 1, x$fs)
x$fs<- ifelse(x$Tmin<=-5 & x$species%in%c("AESHIP", "BETPEN", "ALNRUG"), 1, x$fs)
chill <- read.csv("~/Documents/git/microclimates/analyses/output/clean_gdd_bbanddvr.csv")
head(chill)
ws <- read.csv("~/Documents/git/microclimates/analyses/output/clean_gdd_chill_bbanddvr.csv.csv")
ws <- read.csv("~/Documents/git/microclimates/analyses/output/clean_gdd_chill_bbanddvr.csv")
mean(ws$utah, na.rm=TRUE)
mean(ws$utah[(ws$type=="Treespotters")], na.rm=TRUE)
mean(ws$utah[(ws$type=="Harvard Forest")], na.rm=TRUE)
hl <- read.csv("~/Documents/git/microclimates/analyses/output/clean_gdd_chill_bbanddvr_hobo.csv")
mean(hl$utah[(hl$type=="Treespotters")], na.rm=TRUE)
mean(hl$utah[(hl$type=="Harvard Forest")], na.rm=TRUE)
mean(hl$gdd_lo[(hl$type=="Treespotters")], na.rm=TRUE)
mean(hl$gdd_lo[(hl$type=="Harvard Forest")], na.rm=TRUE)
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Questions to address:
# GDDlo ~ urban + (urban|species)
## Let's start with Question 1 first...
#library(rethinking)
library(RColorBrewer)
library(viridis)
library(lme4)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(rstan)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 292
sd(ws$gdd_bb, na.rm = TRUE) ## 116
use.urban = TRUE
use.provenance = FALSE
if(use.urban == TRUE & use.provenance == TRUE){
print("Error has occurred. Can't have both urban and provenance equal TRUE!")
}
if(use.urban == FALSE & use.provenance == FALSE){
print("Error has occurred. Can't have both urban and provenance equal TRUE!")
}
# Step 1: Set up years, days per year, temperatures, sampling frequency, required GDD (fstar)
daysperyr <- 250 #### just to make sure we don't get any NAs
nspps <- 12
ninds <- 10
nobs <- nspps*ninds
nsites <- 2
nmicros <- 10
if(use.urban==TRUE){
urbeffect <- -75
#urbsd <- 20 ### only used when using provenance
}
if(use.provenance==TRUE){
proveffect <- -10
}
fstar <- 250
fstarspeciessd <- 20
fstarindsd <- 10
dayz <- rep(1:daysperyr, nobs)
cc.arb <- 11 ## based off weather station data
mean.microarb <- 2
sigma.arb <- 8
sigma.microarb <- 1
cc.hf <- 9  ## based off weather station data
mean.microhf <- 2
sigma.hf <- 8
sigma.microhf <- 1
source("simulations/micro_databuildfx.R") ### warning messages are okay - outdated package warning but still works
cols <-viridis_pal(option="viridis")(3)
## Just a quick check on GDDs
quartz()
ggplot(df.fstar, aes(x=fstar.new)) + geom_histogram(aes(fill=site)) + theme_classic() +
scale_fill_manual(name="Site", values=cols, labels=sort(unique(df$site)))
arbmicromeans
arbmicrosigmas
### Okay, first let's check on site level varition in temperature
#### Before moving on, let's look at the data a bit
ws <- ggplot(df, aes(x=tmean.ws)) + geom_histogram(aes(fill=site)) + theme_classic() +
scale_fill_manual(name="Site", values=cols, labels=sort(unique(df$site))) + ggtitle("Weather Station") +
coord_cartesian(xlim=c(-25, 42))
hl <- ggplot(df, aes(x=tmean)) + geom_histogram(aes(fill=site)) + theme_classic() +
scale_fill_manual(name="Site", values=cols, labels=sort(unique(df$site))) + ggtitle("Hobo Logger") +
coord_cartesian(xlim=c(-25, 42))
quartz()
grid.arrange(ws, hl, ncol=2)
quartz()
par(mfrow=c(1,2))
my.pal <- viridis_pal(option="magma")(12)
my.pch <- c(15:16)
plot(bbws.gdd ~ species, col=my.pal[as.factor(bball$species)], pch=my.pch[as.factor(bball$site)], data = bball, main="Weather Station",
ylab="GDD")
abline(h=mean(bball$bbws.gdd), lwd=3)
plot(bbhl.gdd ~ species, col=my.pal[as.factor(bball$species)], pch=my.pch[as.factor(bball$site)], data = bball, main="Hobo Logger",
ylab="GDD")
abline(h=mean(bball$bbhl.gdd), lwd=3)
bball$urban <- ifelse(bball$site=="arb", 1, 0)
datalist.gdd <- with(bball,
list(y = bbws.gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(bball),
n_sp = length(unique(bball$species))
)
)
ws_urb_buildfake = stan('stan/urbanmodel_stan_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2000, control=list(adapt_delta = 0.99)) ###
ws_urb_fake.sum <- summary(ws_urb_buildfake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
## Set seed
set.seed(107844)
## Generate leaf type
leaf <- rbinom(n = 2000, size = 1, prob = .3)
## Conditional sampling
data <- dim(length(leaf))
for(i in 1:length(leaf)){
if(leaf[i] == 0){
data[i] <- rnorm(n = 1, mean = 10, sd = sqrt(5))
} else{
data[i] <- rnorm(n = 1, mean = 25, sd = sqrt(2))
}
}
library(rstan)
options(mc.cores = parallel::detectCores())
## Put simulated data into list for stan
data.stan <- list(N = length(data),
G = data)
## Fit model
fit.stanmarg <- stan("leaf-marg.stan",
data = data.stan,
iter = 4000,
warmup = 2000,
chains = 4)
setwd("~/Documents/git/bayes2020/Projects/Geoff/")
## Fit model
fit.stanmarg <- stan("leaf-marg.stan",
data = data.stan,
iter = 4000,
warmup = 2000,
chains = 4)
mu_fresh = 25
sigma_fresh = 5
mu_dried=10
sigma_dried=5
N=1
n=1
lp[n] = log(exp(normal_lpdf(G[n] | mu_fresh, sigma_fresh)) * p + exp(normal_lpdf(G[n] | mu_dried, sigma_dried)) * (1 - p))
lp[n] = log(exp(normal(G[n] | mu_fresh, sigma_fresh)) * p + exp(normal(G[n] | mu_dried, sigma_dried)) * (1 - p))
lp[n] = log(exp(rnorm(G[n] | mu_fresh, sigma_fresh)) * p + exp(rnorm(G[n] | mu_dried, sigma_dried)) * (1 - p))
G=1
lp[n] = log(exp(rnorm(G[n] | mu_fresh, sigma_fresh)) * p + exp(rnorm(G[n] | mu_dried, sigma_dried)) * (1 - p))
p=0.3
lp[n] = log(exp(rnorm(G[n] | mu_fresh, sigma_fresh)) * p + exp(rnorm(G[n] | mu_dried, sigma_dried)) * (1 - p))
lp <- log(exp(rnorm(G[n] | mu_fresh, sigma_fresh)) * p + exp(rnorm(G[n] | mu_dried, sigma_dried)) * (1 - p))
lp
launch_shinystan(fit.stanmarg)
library(shinystan)
launch_shinystan(fit.stanmarg)
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Questions to address:
# GDDlo ~ urban + (urban|species)
## Let's start with Question 1 first...
#library(rethinking)
library(RColorBrewer)
library(viridis)
library(lme4)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(rstan)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 292
sd(ws$gdd_bb, na.rm = TRUE) ## 116
use.urban = TRUE
use.provenance = FALSE
if(use.urban == TRUE & use.provenance == TRUE){
print("Error has occurred. Can't have both urban and provenance equal TRUE!")
}
if(use.urban == FALSE & use.provenance == FALSE){
print("Error has occurred. Can't have both urban and provenance equal TRUE!")
}
# Step 1: Set up years, days per year, temperatures, sampling frequency, required GDD (fstar)
daysperyr <- 250 #### just to make sure we don't get any NAs
nspps <- 12
ninds <- 10
nobs <- nspps*ninds
nsites <- 2
nmicros <- 10
if(use.urban==TRUE){
urbeffect <- -75
#urbsd <- 20 ### only used when using provenance
}
if(use.provenance==TRUE){
proveffect <- -10
}
fstar <- 250
fstarspeciessd <- 20  ### Not doing this well, try boosting species number and see if helps
fstarindsd <- 10   ### Code it more obviously
dayz <- rep(1:daysperyr, nobs)
cc.arb <- 11 ## based off weather station data
mean.microarb <- 2
sigma.arb <- 8
sigma.microarb <- 1
cc.hf <- 9  ## based off weather station data
mean.microhf <- 2
sigma.hf <- 8
sigma.microhf <- 1
set.seed(12321)
if(use.urban==TRUE){
provenance.arb <- round(rnorm(nobs, 42.5, 8), digits=2)
provenance.hf <- 42.5
fstar <- round(rnorm(nspps, fstar, fstarspeciessd), digits=0)
df.fstar <- as.data.frame(cbind(species=rep(1:nspps, each=ninds*nsites), inds=1:ninds, fstar=rep(fstar, each=ninds*nsites),
site=rep(c("arb", "hf"), each=ninds)))
df.fstar$fstar <- as.numeric(df.fstar$fstar)
df.fstar$sp_ind <- paste(df.fstar$species, df.fstar$inds, sep="_")
df.fstar$fstar.new <- round(ifelse(df.fstar$site=="hf", rnorm(df.fstar$inds, df.fstar$fstar, fstarindsd),
rnorm(df.fstar$inds, df.fstar$fstar+urbeffect, fstarindsd)), digits=0)
}
# Step 2: find GDDs
arbmicromeans <- rnorm(nmicros, cc.arb, mean.microarb)
arbmicrosigmas <- rnorm(nmicros, sigma.arb, sigma.microarb)
arbclim <- data.frame(site=rep(c(1:nmicros), each=daysperyr), means=rep(arbmicromeans, each=daysperyr),
sigmas=rep(arbmicrosigmas, each=daysperyr), day=rep(c(1:daysperyr), nmicros))
arbclim
View(arbclim)
arbclim$tmean <- rnorm(arbclim$day, arbclim$means, arbclim$sigmas)
hfmicromeans <- rnorm(nmicros, cc.hf, mean.microhf)
hfmicrosigmas <- rnorm(nmicros, sigma.hf, sigma.microhf)
hfclim <- data.frame(site=rep(c(1:nmicros), each=daysperyr), means=rep(hfmicromeans, each=daysperyr),
sigmas=rep(hfmicrosigmas, each=daysperyr), day=rep(c(1:daysperyr), nmicros))
hfclim$tmean <- rnorm(hfclim$day, hfclim$means, hfclim$sigmas)
# Step 3: Make a data frame and get the mean temp per year (to double check the data)
df.arb <- data.frame(cbind(doy=dayz, tmean=round(arbclim$tmean, digits=2),
species=as.character(rep(1:nspps, each=daysperyr)),
ind=as.character(rep(1:ninds, each=daysperyr*nspps)),
site="arb",
provenance = rep(provenance.arb, each=daysperyr)))
df.hf <- data.frame(cbind(doy=dayz, tmean=round(hfclim$tmean, digits=2),
species=as.character(rep(1:nspps, each=daysperyr)),
ind=as.character(rep(1:ninds, each=daysperyr*nspps)),
site="hf",
provenance = provenance.hf))
df <- full_join(df.arb, df.hf)
df$tmean <- as.numeric(df$tmean)
df$microsite <- paste0(df$site, df$ind)
df$tmean.ws <- ave(df$tmean, df$doy, df$site)
View(df)
rm(list=ls())
options(stringsAsFactors = FALSE)
library(dplyr)
library(tidyr)
# Setting working directory
setwd("~/Documents/git/regionalrisk/analyses/")
########################
#### get the data - must choose the dataframe for specific analyses
#fs<-read.csv("output/fs_allspp_dvr.csv", header=TRUE)
#fs<-read.csv("output/fs_allspp_five.csv", header=TRUE)
#fs<-read.csv("output/fs_allspp_original.csv", header=TRUE)
#fs<-read.csv("output/fs_allspp_fullleaf.csv", header=TRUE)
fs<-read.csv("output/fs_allspp_midleaf.csv", header=TRUE)
fs<-subset(fs, select=c("lat", "long", "fs.count", "year", "species", "fs"))
mat<-read.csv("output/mat_MAM.csv", header=TRUE)
mat<-subset(mat, year>1950)
elev<-read.csv("output/fs_bb_sitedata.csv", header=TRUE)
elev<-subset(elev, year>1950)
nao<-read.csv("output/nao_NovApr.csv", header=TRUE)
nao<-subset(nao, year>1950)
elev<-dplyr::select(elev, species, LAT, LON, ALT)
elev<-elev%>%rename(lat=LAT)%>%rename(long=LON)%>%rename(elev=ALT)
elev$lat.long<-paste(elev$lat, elev$long)
elev<-elev[!duplicated(elev),]
matelev<-full_join(elev, mat)
#### Get elevation information
matelev$cc<-ifelse(matelev$year<=1983&matelev$year>1950, 0, 1)
fs<-dplyr::select(fs, lat, long, species, fs.count, year)
fs<-fs[!duplicated(fs),]
fspreds<-full_join(matelev, fs)
fspreds<-na.omit(fspreds)
fspreds<-fspreds[!duplicated(fspreds),]
fspreds$elev<-ave(fspreds$elev, fspreds$lat.long)
fspreds<-fspreds[!duplicated(fspreds),]
nao<-dplyr::select(nao, year, nao)
nao<-nao[!duplicated(nao),]
fspreds<-full_join(fspreds, nao)
dist<-read.csv("output/dist_wgs.csv", header=TRUE)
dist<-dist%>%rename(long=LONG)%>%rename(lat=LAT)
fspreds<-full_join(fspreds, dist)
write.csv(fspreds, file="~/Documents/git/regionalrisk/analyses/output/fs_allspp_midleaf_allpred.csv", row.names = FALSE)
