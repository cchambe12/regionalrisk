"Tilia platyphyllos - 50% (Lenz et al., 2016)"=expression(paste(italic("Tilia platyphyllos"), "- 50% (Lenz et al., 2016)")),
"Sorbus aucuparia - 50% (Lenz et al., 2016"=expression(paste(italic("Sorbus aucuparia"), "- 50% (Lenz et al., 2016")),
"Prunus avium - 50% (Lenz et al., 2016)"=expression(paste(italic("Prunus avium"), "- 50% (Lenz et al., 2016)")),
"Rice - 100% (Sanchez et al., 2013)"="Rice - 100% (Sanchez et al., 2013)",
"All species (Cannell & Smith, 1986)"="All species (Cannell & Smith, 1986)",
"Corn - 100% (Sanchez et al., 2013)"="Corn - 100% (Sanchez et al., 2013)",
"Vaccinium spp. (Longstroth, 2012)"=expression(paste(italic("Vaccinium spp."), "(Longstroth, 2012)")),
"Wheat - 10 to 90% (Barlow et al., 2015)"="Wheat - 10 to 90% (Barlow et al., 2015)",
"Wheat - 100% (Barlow et al., 2015)"="Wheat - 100% (Barlow et al., 2015)",
"Rosaceae - 10% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 10% (Longstroth, 2013)")),
"Rosaceae - 90% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 90% (Longstroth, 2013)")),
"Wheat - 100% (Sanchez et al., 2013)"="Wheat - 100% (Sanchez et al., 2013)"))
temp<- temp + scale_x_discrete(labels=c("All species - soft freeze (Augspurger, 2013)"="All species - soft freeze (Augspurger, 2013)",
"All species (Peterson & Abatzoglou, 2014)"="All species (Peterson & Abatzoglou, 2014)",
"All species - hard freeze (Schwartz, 1993))"="All species - hard freeze (Schwartz, 1993))",
"Fagus sylvatica - 50% (Lenz et al., 2016)" = expression(paste(italic("Fagus sylvatica"),  "- 50% (Lenz et al., 2016)")),
"Eucalyptus pauciflora (Barker et al., 2005)"=expression(paste(italic("Eucalyptus pauciflora"), "(Barker et al., 2005)")),
"Acer pseudoplatanus - 50% (Lenz et al., 2016)"=expression(paste(italic("Acer pseudoplatanus"), "- 50% (Lenz et al., 2016)")),
"Tilia platyphyllos - 50% (Lenz et al., 2016)"=expression(paste(italic("Tilia platyphyllos"), "- 50% (Lenz et al., 2016)")),
"Sorbus aucuparia - 50% (Lenz et al., 2016"=expression(paste(italic("Sorbus aucuparia"), "- 50% (Lenz et al., 2016")),
"Prunus avium - 50% (Lenz et al., 2016)"=expression(paste(italic("Prunus avium"), "- 50% (Lenz et al., 2016)")),
"Rice - 100% (Sanchez et al., 2013)"="Rice - 100% (Sanchez et al., 2013)",
"All species (Cannell & Smith, 1986)"="All species (Cannell & Smith, 1986)",
"Corn - 100% (Sanchez et al., 2013)"="Corn - 100% (Sanchez et al., 2013)",
"Vaccinium spp. (Longstroth, 2012)"=expression(paste(italic("Vaccinium spp."), "(Longstroth, 2012)")),
"Wheat - 10 to 90% (Barlow et al., 2015)"="Wheat - 10 to 90% (Barlow et al., 2015)",
"Wheat - 100% (Barlow et al., 2015)"="Wheat - 100% (Barlow et al., 2015)",
"Rosaceae - 10% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 10% (Longstroth, 2013)")),
"Rosaceae - 90% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 90% (Longstroth, 2013)")),
"Wheat - 100% (Sanchez et al., 2013)"="Wheat - 100% (Sanchez et al., 2013)"))
temp<-ggplot(d, aes(x=dataset, y=temperature)) +
geom_linerange(aes(ymin=temperature-sd, ymax=temperature+sd, color=sector), alpha=0.3) +
geom_point(aes(shape=phase, color=sector)) + ylab(my.xlab) + theme(axis.title.y=element_blank()) +
geom_hline(yintercept=0, linetype=2) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black")) +
ylim(c(-20, 10))
temp<- temp + scale_x_discrete(labels=c("All species - soft freeze (Augspurger, 2013)"="All species - soft freeze (Augspurger, 2013)",
"All species (Peterson & Abatzoglou, 2014)"="All species (Peterson & Abatzoglou, 2014)",
"All species - hard freeze (Schwartz, 1993))"="All species - hard freeze (Schwartz, 1993))",
"Fagus sylvatica - 50% (Lenz et al., 2016)" = expression(paste(italic("Fagus sylvatica"),  "- 50% (Lenz et al., 2016)")),
"Eucalyptus pauciflora (Barker et al., 2005)"=expression(paste(italic("Eucalyptus pauciflora"), "(Barker et al., 2005)")),
"Acer pseudoplatanus - 50% (Lenz et al., 2016)"=expression(paste(italic("Acer pseudoplatanus"), "- 50% (Lenz et al., 2016)")),
"Tilia platyphyllos - 50% (Lenz et al., 2016)"=expression(paste(italic("Tilia platyphyllos"), "- 50% (Lenz et al., 2016)")),
"Sorbus aucuparia - 50% (Lenz et al., 2016"=expression(paste(italic("Sorbus aucuparia"), "- 50% (Lenz et al., 2016")),
"Prunus avium - 50% (Lenz et al., 2016)"=expression(paste(italic("Prunus avium"), "- 50% (Lenz et al., 2016)")),
"Rice - 100% (Sanchez et al., 2013)"="Rice - 100% (Sanchez et al., 2013)",
"All species (Cannell & Smith, 1986)"="All species (Cannell & Smith, 1986)",
"Corn - 100% (Sanchez et al., 2013)"="Corn - 100% (Sanchez et al., 2013)",
"Vaccinium spp. (Longstroth, 2012)"=expression(paste(italic("Vaccinium spp."), "(Longstroth, 2012)")),
"Wheat - 10 to 90% (Barlow et al., 2015)"="Wheat - 10 to 90% (Barlow et al., 2015)",
"Wheat - 100% (Barlow et al., 2015)"="Wheat - 100% (Barlow et al., 2015)",
"Rosaceae - 10% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 10% (Longstroth, 2013)")),
"Rosaceae - 90% (Longstroth, 2013)"=expression(paste(italic("Rosaceae"), "- 90% (Longstroth, 2013)")),
"Wheat - 100% (Sanchez et al., 2013)"="Wheat - 100% (Sanchez et al., 2013)"))
temp +coord_flip()
Vcmax <- function (Vmo, Tvlo, Tv) {  #Vmo = 23, Tvlo = 277.15 are constants
(Vmo * (exp(3000 * (1/288.15 -1/Tv)))) /
((1 + exp(.4 * (Tvlo - Tv))) * (1 + exp(0.4 * (Tv - 318.15))))
}
## compensation point
comp <- function(Tv) { 21.2 * exp(5000 * ((1/288.15) - (1/Tv))) } #units: umol/mol
## K1 and K2
K1 <- function(Tv) { 150 * exp(6000 * ((1/288.15) - (1/Tv))) }
K2 <- function(Tv) {0.836 * exp(-1400 * ((1/288.15) - (1/Tv))) }
## el and ea
convertTv <- function(Tv) {
TvC <- Tv -273.15
return(TvC)
}
el <- function(Tv) {
TvC <- convertTv(Tv)
el <- 0.611 * exp((17.502 * TvC)/(TvC + 240.97))
return(el)
}
ea <- function (relHum, Tv) {
relHum /(100 * el(Tv))  # changed from multiplication to divide; Campbell and Norman page 42
}
input.df <- dummy
farquhar_solver <- function (input.df, stomata = c('open', 'closed')) {
## input.df needs to have columns for Tv, PAR, Ca and relhum. the rest can be calculated...
## defaults that we'd like to avoid including in the giant function call
gamma <- 0.015
Vmo <- 23 #92 #35
b <- 2
alpha <- 0.04
Do <- 1.3
M <- 9  #stomatal slope; unitless; Raczka et al 2016, Biogeosciences; (also Heroult 2013, Plant Cell & Environment)
Tvlo <- 277.85
## Functions used to calculate other inputs from input.df
input.df$Vcmax <- Vcmax(Vmo = Vmo, Tvlo = Tvlo, Tv = input.df$Tv )
input.df$comp <- comp(Tv = input.df$Tv)
input.df$el <- el(Tv = input.df$Tv)
input.df$ea <- ea(Tv = input.df$Tv, relHum = input.df$relHum)
# calculated inputs
input.df$Rd <- gamma * input.df$Vcmax
input.df$k1.dat <- K1(input.df$Tv)
input.df$k2.dat <- K2(input.df$Tv)
# substitutions for simplification in quadratics
input.df$X = input.df$k1.dat * (1 + input.df$k2.dat) # X = K1*(1+K2)
input.df$Y <- alpha * input.df$PAR  # Y = alpha*PAR
# F = (Ca - comp) * (1 + ((el - ea)/Do))
input.df$FF <- ((input.df$Ca - input.df$comp) * (1 + ((input.df$el - input.df$ea)/Do)))
### relevant functions
# A1 = [(Vcmax * (Ci - comp)) / (Ci + K1 * (1+K2)) ] - Rd
# A1 = [(Vcmax * (Ci - comp)) / (Ci + X) ] - Rd
A1<- function(Ci, input.df) {
A <- ((input.df$Vcmax * (Ci - input.df$comp)) / (Ci + input.df$X)) - input.df$Rd
return(A)
}
# A2 = [ alpha * PAR * (Ci - comp) / (Ci + 2comp) ] - Rd
A2 <- function(Ci, input.df) {
A <- (alpha * input.df$PAR * ((Ci - input.df$comp) / (Ci + 2 * input.df$comp))) - input.df$Rd
return(A)
}
#
# #Actually want to be solving for and minimizing J (post-quadratic) and minimizing, THEN subtracting R
#
# J1 <- function(Ci, input.df) {
#    J <- ((input.df$Vcmax * (Ci - input.df$comp)) / (Ci + input.df$X))
#    return(J)
# }
#
# J2 <- function(Ci, input.df) {
#    J <- (alpha * input.df$PAR * ((Ci - input.df$comp) / (Ci + 2 * input.df$comp)))
#    return(J)
# }
#
### stomata closed ###
if(stomata == 'closed') {
### CO2 limited case, coefficients for polyroot function
aa <- (b * input.df$X * input.df$Ca/1.6) + (input.df$Vcmax * input.df$comp) + (input.df$Rd * input.df$X)
bb <- (input.df$Rd) + (b * input.df$Ca / 1.6) - (b * input.df$X / 1.6) - (input.df$Vcmax)
cc <- (-b / 1.6)
z <- data.frame(aa = aa, bb = bb, cc = cc)  # where aa + bb*c1 + cc*c1^2
#solve the polynomial
roots <- apply(z, 1, polyroot)
if(round(Im(roots[1]), 10) != 0) {
stop("quadratic roots are imaginary")
}
#coerce into non-imaginary components
roots.num <- Re(roots)
#extract the non-negative value
Ci.extract.A1 <- apply(roots.num, 2, max)
# calculate A
AA1 <- A1(Ci = Ci.extract.A1, input.df = input.df)
### Light limited case, coefficients for polyroot function
aa <- ((b * 2 * input.df$comp * input.df$Ca / 1.6) + (input.df$Rd * 2 * input.df$comp) + (input.df$Y * input.df$comp))
bb <- (input.df$Rd + (b * input.df$Ca / 1.6) - (b * 2 * input.df$comp / 1.6) - input.df$Y)
cc <- (-b / 1.6)
# define polynomial roots for each data point
z <- data.frame(aa = aa, bb = bb, cc = cc)  # where aa + bb*c1 + cc*c1^2
#solve the polynomial
roots <- apply(z, 1, polyroot)
if(round(Im(roots[1]), 10) != 0) {
stop("quadratic roots are imaginary")
}
#coerce into non-imaginary components
roots.num <- Re(roots)
# extract the non-negative value
Ci.extract.A2 <- apply(roots.num, 2, max)
# calculate A2
AA2 <- A2(Ci = Ci.extract.A2, input.df = input.df)  # only works if PAR has values 6 orders of magnitude higher
### Build output data frame
# pick minimum for each time point:
A.df <- data.frame (AA1 = AA1, AA2 = AA2, Ci.A1 = Ci.extract.A1, Ci.A2 = Ci.extract.A2)
A.df$A.min <- apply(A.df[,1:2], 1, min)
A.df$min.eq <- apply(A.df[,1:2], 1, which.min)
## Solve for gsw ##
# stomata closed, gsw = b
A.df$gsw <- rep(b, dim(A.df)[1])
}
#### Stomata Open ###
if(stomata == 'open') {
############ vvvvv THIS IS WRONG!!!!!!! vvvvv ************
### CO2 limited coefficients
aa <- ((b * input.df$X * input.df$Ca * input.df$FF) + (1.6 * input.df$FF * input.df$Vcmax * input.df$comp) - (1.6 * input.df$FF * input.df$Rd * input.df$X) -
(M * input.df$Vcmax * input.df$comp * input.df$Ca) + (M * input.df$Rd * input.df$X * input.df$Ca))
bb <- ((-input.df$FF * b * input.df$Ca) - (b * input.df$X) - (1.6 * input.df$FF * input.df$Vcmax) + (1.6 * input.df$FF * input.df$Rd) + (M * input.df$Vcmax * input.df$Ca) +
(M * input.df$Vcmax * input.df$comp) - (input.df$Rd * M * input.df$Ca) + (M * input.df$Rd * input.df$X))
cc <- ((-b * input.df$FF) + (M * input.df$Vcmax) - (M * input.df$Rd))
############ ^^^^^ THIS IS WRONG!!!!!!! ^^^^^ ************
# define polynomial roots for each data point
z <- data.frame(aa = aa, bb = bb, cc = cc)  # where aa + bb*c1 + cc*c1^2
#solve the polynomial
roots <- apply(z, 1, polyroot)
if(round(Im(roots[1]), 10) != 0) {
stop("quadratic roots are imaginary")
}
#coerce into non-imaginary components
roots.num <- Re(roots)
#extract the non-negative value
Ci.extract.A1 <- apply(roots.num, 2, max)
#calculate A1
AA1 <- A1(Ci = Ci.extract.A1, input.df = input.df)
### Light-limited coefficients
aa <- ((b * input.df$FF * input.df$Ca * 2 * input.df$comp) - (1.6 * input.df$FF * input.df$Y * input.df$comp) + (1.6 * input.df$FF * input.df$Rd * 2 * input.df$comp) -
(M * input.df$Ca * input.df$Y * input.df$comp) + (M * input.df$Rd * 2 * input.df$comp * input.df$Ca))
bb <- ((b * input.df$FF * input.df$Ca) - (b * input.df$FF * 2 * input.df$comp) - (1.6 * input.df$FF * input.df$Y) + (1.6 * input.df$FF * input.df$Rd) + (M * input.df$Y * input.df$Ca) +
(M * input.df$Y * input.df$comp) - (M * input.df$Rd * input.df$Ca) - (M * input.df$Rd * 2 * input.df$comp))
cc <- ((-b * input.df$FF) - (M * input.df$Y) + (M * input.df$Rd))
# define polynomial roots for each data point
z <- data.frame(aa = aa, bb = bb, cc = cc)  # where aa + bb*c1 + cc*c1^2
#solve the polynomial
roots <- apply(z, 1, polyroot)
if(round(Im(roots[1]), 10) != 0) {
stop("quadratic roots are imaginary")
}
# coerce into non-imaginary components
roots.num <- Re(roots)
# extract the non-negative value
Ci.extract.A2 <- apply(roots.num, 2, max)
# calculate A2
AA2 <- A2(Ci = Ci.extract.A2, input.df = input.df)  # only works if PAR has values 6 orders of magnitude higher
### build output data frame
# pick minimum for each time point:
A.df <- data.frame (AA1 = AA1, AA2 = AA2, Ci.A1 = Ci.extract.A1, Ci.A2 = Ci.extract.A2)
A.df$A.min <- apply(A.df[,1:2], 1, min)
A.df$min.eq <- apply(A.df[,1:2], 1, which.min)
### solve for gsw ###
gsw.solve <- ((M * A.df$A.min)/((input.df$Ca - input.df$comp) * (1 + ((input.df$el - input.df$ea)/Do)))) + b
A.df$gsw <- gsw.solve
}
return(A.df)
}
##### Applying the farquhar_solver function #####
farquhar_solver(input.df = dummy, stomata = 'closed')
farquhar_solver(input.df = dummy, stomata = 'open')
#### Check against plantecophs package... ####
dummy$el <- el(Tv = dummy$Tv)
dummy$ea <- ea(relHum = dummy$relHum, Tv = dummy$Tv)
dummy$VPD<- dummy$el-dummy$ea
dummy$Tair<-dummy$Tv-273.15
FARAO(Ca=dummy$Ca, VPD=dummy$VPD, Tair=dummy$Tair)
#### Now look at real data to compare ####
dat <- read.csv('~/Documents/git/scaling_farquhar/Aggregated_Climate_Data.csv', header=TRUE)
dat$Tv <- dat$Air_Temp_K
dat$Tv<-ave(dat$Tv, dat$month, dat$year, dat$day, dat$hour)
dat$relHum <- dat$Relative_Humidity_Percent
dat$relHum<-ave(dat$relHum, dat$month, dat$year, dat$day, dat$hour)
dat$Ca <- as.numeric(dat$Atmospheric_CO2)
dat$Ca <- ave(dat$Ca, dat$month, dat$year, dat$day, dat$hour)
dat$comp <- comp(Tv = dat$Tv)
dat$comp<-ave(dat$comp, dat$month, dat$year, dat$day, dat$hour)
dat$Vcmax <- Vcmax(Vmo = 35, Tv = dat$Tv, Tvlo=277.85)
dat$Vcmax<-ave(dat$Vcmax, dat$month, dat$year, dat$day, dat$hour)
dat$el <- el(Tv = dat$Tv)
dat$el<-ave(dat$el, dat$month, dat$year, dat$day, dat$hour)
dat$ea <- ea(relHum = dat$relHum, Tv = dat$Tv)
dat$ea<-ave(dat$ea, dat$month, dat$year, dat$day, dat$hour)
dat$PAR <- dat$Par_moles_m2_s * 1000000 ### only keep this until push updated to git
dat$PAR<-ave(dat$PAR, dat$month, dat$year, dat$day, dat$hour)
dat$time<-dat$hour
library(dplyr)
dat.check<-dat%>%filter(year==2013)%>%filter(month==8)%>%filter(day==13)%>% ### choose this date due to LAI information
dplyr::select(hour, Tv, relHum, Ca, comp, Vcmax, el, ea, PAR, time)
dat.check<-dat.check[!duplicated(dat.check),]
dat.check<-dat.check[(dat.check$time<24),]
library(plantecophys)
dat.check$VPD<- dat.check$el-dat.check$ea
#dat.check$VPDx<-RHtoVPD(dat.check$relHum, TdegC = dat.check$Tv-273.15)
dat.check$Tair<-dat.check$Tv-273.15
FARAO(Ca=dat.check$Ca, VPD=dat.check$VPD, Tair=dat.check$Tair, PPFD=dat.check$PAR)
lai <- read.csv('~/Documents/git/scaling_farquhar/hf150-01-hem-lai.csv', header=TRUE)
lai<-lai%>%filter(date=="2013-08-13")
lai$lai.sum<-ave(lai$lai.masked, FUN=sum) ## 54.28
###make a data frame for FARAO out put
eco.phys.sol<-as.data.frame(FARAO(Ca=dat.check$Ca, VPD=dat.check$VPD, Tair=dat.check$Tair))
##add a column for the lai sums from harvard forest
eco.phys.sol$HF.lai<-lai$lai.sum
###multiply them together to get the footprint level A
eco.phys.sol$A.footprint<-eco.phys.sol$HF.la*eco.phys.sol$ALEAF
eco.phys.sol$hour<-1:24
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))
library(ggplot2)
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))
colnames(eco.phys.sol)
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point()
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point() + geom_line(aes(x=hour, y=ALEAF))
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point(col="green") + geom_line(aes(x=hour, y=ALEAF), col="green") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.ticks.y = element_blank())
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point(col="forestgreen") + geom_line(aes(x=hour, y=ALEAF), col="forestgreen") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.ticks.y = element_blank())
farquhar_solver(input.df = dat.check, stomata = 'open')
far<-as.data.frame(farquhar_solver(input.df = dat.check, stomata = 'open'))
eco.phys.sol$A<-far$AA2
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point(col="forestgreen") + geom_line(aes(x=hour, y=ALEAF), col="forestgreen") +
geom_line(aes(x=hour, y=A), col="steelblue") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.ticks.y = element_blank())
eco.phys.sol$A<-far$AA1
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point(col="forestgreen") + geom_line(aes(x=hour, y=ALEAF), col="forestgreen") +
geom_line(aes(x=hour, y=A), col="steelblue") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.ticks.y = element_blank())
eco.phys.sol$A<-far$A.min
ggplot(eco.phys.sol, aes(x=hour, y=ALEAF))+geom_point(col="forestgreen") + geom_line(aes(x=hour, y=ALEAF), col="forestgreen") +
geom_line(aes(x=hour, y=A), col="steelblue") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.ticks.y = element_blank())
rm(list=ls())
options(stringsAsFactors = FALSE)
library(ggplot2)
library(rstanarm)
library(dplyr)
library(tidyr)
library(brms)
library(ggstance)
setwd("~/Documents/git/regionalrisk/analyses")
d<-read.csv("output/fs_bb_sitedata.csv", header=TRUE)
View(d)
########################
#### get the data
dx<-read.csv("output/fs_matspspace.csv", header=TRUE)
View(dx)
length(unique(dx$PEP_ID))
length(unique(dx$lat.long))
d<-read.csv("fs_yearsitespp.csv", header=TRUE)
### Load data
setwd("~/Documents/git/regionalrisk/analyses/output")
d<-read.csv("fs_yearsitespp.csv", header=TRUE)
d$lat.long<-paste(d$lat, d$long)
length(unique(d$lat.long))
length(unique(PEP_ID))
length(unique(d$PEP_ID))
############# Add in Budburst data? ###########################
bb.aes<-read.csv("output/bbch_region_aesculus.csv", header=TRUE)
############# Add in Budburst data? ###########################
bb.aes<-read.csv("bbch_region_aesculus.csv", header=TRUE)
col.names(bb.aes)
colnames(bb.aes)
## Using BBCH 11 for analysis
# AESHIP
bb.aes$lat.long<-paste(bb.aes$LAT, bb.aes(LON))
## Using BBCH 11 for analysis
# AESHIP
bb.aes$lat.long<-paste(bb.aes$LAT, bb.aes$LON)
length(unique(bb.aes$lat.long))
length(unique(bb.aes$PEP_ID))
rm(list=ls())
options(stringsAsFactors = FALSE)
# Load Libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(egg)
library(brms)
# Setting working directory
setwd("~/Documents/git/regionalrisk/analyses/")
############# Add in Budburst data? ###########################
bb.aes<-read.csv("output/bbch_region_aesculus.csv", header=TRUE)
bb.ag<-read.csv("output/bbch_region_alnus.csv", header=TRUE)
bb.bp<-read.csv("output/bbch_region_betula.csv", header=TRUE)
bb.fsyl<-read.csv("output/bbch_region_fagus.csv", header=TRUE)
bb.fex<-read.csv("output/bbch_region_fraxinus.csv", header=TRUE)
bb.qr<-read.csv("output/bbch_region_quercus.csv", header=TRUE)
bb.aes$lat.long<-paste(bb.aes$LAT, bb.aes$LON)
bb.aes<-bb.aes%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.aes$leafout<-ave(bb.aes$DAY) ## 111.24
bb.aes$bb<-bb.aes$DAY-12
bb.aes$cc<-ifelse(bb.aes$YEAR<=1983, 0, 1)
bb.aes$bb.cc<-ave(bb.aes$bb, bb.aes$cc) ## 0 = 114.27 & 1 = 107.28
bb.aes$decade<-substr(bb.aes$YEAR,3,3)
bb.aes$bb.decade<-NA
bb.aes$bb.decade<-ifelse(bb.aes$decade==5, 1, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==6, 2, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==7, 3, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==8, 4, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==9, 5, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==0, 6, bb.aes$bb.dec)
bb.aes$bb.decade<-ifelse(bb.aes$decade==1, 7, bb.aes$bb.dec)
bb.aes$bb.dec<-ave(bb.aes$bb, bb.aes$bb.decade)
## 50s=114.76; 60s=114.28; 70s=115.11; 80s=112.93; 90s=107.01; 00s=103.41; 10s=103.98
bb.aes$bb.yr<-ave(bb.aes$bb, bb.aes$YEAR)
bb.aes$bb.space<-ave(bb.aes$bb, bb.aes$lat.long)
bb.aes<-rename(bb.aes, year=YEAR)
bb.aes<-dplyr::select(bb.aes, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.aes<-bb.aes[!duplicated(bb.aes),]
# ALNGLU
bb.ag$lat.long<-paste(bb.ag$LAT, bb.ag$LON)
bb.ag<-bb.ag%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.ag$leafout<-ave(bb.ag$DAY)
bb.ag$bb<-bb.ag$DAY-12
bb.ag$cc<-ifelse(bb.ag$YEAR<=1983, 0, 1)
bb.ag$bb.cc<-ave(bb.ag$bb, bb.ag$cc) ## 0 = 114.88 & 1 = 106.93
bb.ag$decade<-substr(bb.ag$YEAR,3,3)
bb.ag$bb.decade<-NA
bb.ag$bb.decade<-ifelse(bb.ag$decade==5, 1, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==6, 2, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==7, 3, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==8, 4, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==9, 5, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==0, 6, bb.ag$bb.dec)
bb.ag$bb.decade<-ifelse(bb.ag$decade==1, 7, bb.ag$bb.dec)
bb.ag$bb.dec<-ave(bb.ag$bb, bb.ag$bb.decade)
## 50s=118.65; 60s=116.06; 70s=114.20; 80s=112.30; 90s=104.96; 00s=105.98; 10s=104.74
bb.ag$bb.yr<-ave(bb.ag$bb, bb.ag$YEAR)
bb.ag$bb.space<-ave(bb.ag$bb, bb.ag$lat.long)
bb.ag<-rename(bb.ag, year=YEAR)
bb.ag<-dplyr::select(bb.ag, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.ag<-bb.ag[!duplicated(bb.ag),]
# BETPEN
bb.bp$lat.long<-paste(bb.bp$LAT, bb.bp$LON)
bb.bp<-bb.bp%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.bp$leafout<-ave(bb.bp$DAY)
bb.bp$bb<-bb.bp$DAY-12
bb.bp$cc<-ifelse(bb.bp$YEAR<=1983, 0, 1)
bb.bp$bb.cc<-ave(bb.bp$bb, bb.bp$cc) ## 0 = 113.38 & 1 = 107.46
bb.bp$decade<-substr(bb.bp$YEAR,3,3)
bb.bp$bb.decade<-NA
bb.bp$bb.decade<-ifelse(bb.bp$decade==5, 1, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==6, 2, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==7, 3, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==8, 4, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==9, 5, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==0, 6, bb.bp$bb.dec)
bb.bp$bb.decade<-ifelse(bb.bp$decade==1, 7, bb.bp$bb.dec)
bb.bp$bb.dec<-ave(bb.bp$bb, bb.bp$bb.decade)
## 50s=114.31; 60s=113.13; 70s=113.73; 80s=112.75; 90s=105.77; 00s=105.59; 10s=103.90
bb.bp$bb.yr<-ave(bb.bp$bb, bb.bp$YEAR)
bb.bp$bb.space<-ave(bb.bp$bb, bb.bp$lat.long)
bb.bp<-rename(bb.bp, year=YEAR)
bb.bp<-dplyr::select(bb.bp, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.bp<-bb.bp[!duplicated(bb.bp),]
# FAGSYL
bb.fsyl$lat.long<-paste(bb.fsyl$LAT, bb.fsyl$LON)
bb.fsyl<-bb.fsyl%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.fsyl$leafout<-ave(bb.fsyl$DAY)
bb.fsyl$bb<-bb.fsyl$DAY-12
bb.fsyl$cc<-ifelse(bb.fsyl$YEAR<=1983, 0, 1)
bb.fsyl$bb.cc<-ave(bb.fsyl$bb, bb.fsyl$cc) ## 0 = 121.11 & 1 = 115.74
bb.fsyl$decade<-substr(bb.fsyl$YEAR,3,3)
bb.fsyl$bb.decade<-NA
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==5, 1, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==6, 2, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==7, 3, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==8, 4, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==9, 5, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==0, 6, bb.fsyl$bb.dec)
bb.fsyl$bb.decade<-ifelse(bb.fsyl$decade==1, 7, bb.fsyl$bb.dec)
bb.fsyl$bb.dec<-ave(bb.fsyl$bb, bb.fsyl$bb.decade)
## 50s=120.11; 60s=120.27; 70s=122.27; 80s=120.94; 90s=115.74; 00s=114.00; 10s=111.63
bb.fsyl$bb.yr<-ave(bb.fsyl$bb, bb.fsyl$YEAR)
bb.fsyl$bb.space<-ave(bb.fsyl$bb, bb.fsyl$lat.long)
bb.fsyl<-rename(bb.fsyl, year=YEAR)
bb.fsyl<-dplyr::select(bb.fsyl, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.fsyl<-bb.fsyl[!duplicated(bb.fsyl),]
# FRAEXC
bb.fex$lat.long<-paste(bb.fex$LAT, bb.fex$LON)
bb.fex<-bb.fex%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.fex$leafout<-ave(bb.fex$DAY)
bb.fex$bb<-bb.fex$DAY-12
bb.fex$cc<-ifelse(bb.fex$YEAR<=1983, 0, 1)
bb.fex$bb.cc<-ave(bb.fex$bb, bb.fex$cc) ## 0 = 131.43 & 1 = 125.52
bb.fex$decade<-substr(bb.fex$YEAR,3,3)
bb.fex$bb.decade<-NA
bb.fex$bb.decade<-ifelse(bb.fex$decade==5, 1, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==6, 2, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==7, 3, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==8, 4, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==9, 5, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==0, 6, bb.fex$bb.dec)
bb.fex$bb.decade<-ifelse(bb.fex$decade==1, 7, bb.fex$bb.dec)
bb.fex$bb.dec<-ave(bb.fex$bb, bb.fex$bb.decade)
## 50s=131.69; 60s=129.84; 70s=132.31; 80s=132.16; 90s=125.35; 00s=123.19; 10s=121.47
bb.fex$bb.yr<-ave(bb.fex$bb, bb.fex$YEAR)
bb.fex$bb.space<-ave(bb.fex$bb, bb.fex$lat.long)
bb.fex<-rename(bb.fex, year=YEAR)
bb.fex<-dplyr::select(bb.fex, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.fex<-bb.fex[!duplicated(bb.fex),]
# QUEROB
bb.qr$lat.long<-paste(bb.qr$LAT, bb.qr$LON)
bb.qr<-bb.qr%>%filter(BBCH==11)%>%filter(YEAR>=1950)
bb.qr$leafout<-ave(bb.qr$DAY)
bb.qr$bb<-bb.qr$DAY-12
bb.qr$cc<-ifelse(bb.qr$YEAR<=1983, 0, 1)
bb.qr$bb.cc<-ave(bb.qr$bb, bb.qr$cc) ## 0 = 127.93.59 & 1 = 121.62.31
bb.qr$decade<-substr(bb.qr$YEAR,3,3)
bb.qr$bb.decade<-NA
bb.qr$bb.decade<-ifelse(bb.qr$decade==5, 1, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==6, 2, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==7, 3, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==8, 4, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==9, 5, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==0, 6, bb.qr$bb.dec)
bb.qr$bb.decade<-ifelse(bb.qr$decade==1, 7, bb.qr$bb.dec)
bb.qr$bb.dec<-ave(bb.qr$bb, bb.qr$bb.decade)
## 50s=127.14; 60s=126.64; 70s=129.52; 80s=127.58; 90s=122.1; 00s=118.37; 10s=116.33
bb.qr$bb.yr<-ave(bb.qr$bb, bb.qr$YEAR)
bb.qr$bb.space<-ave(bb.qr$bb, bb.qr$lat.long)
bb.qr<-rename(bb.qr, year=YEAR)
bb.qr<-dplyr::select(bb.qr, species, year, bb, cc, bb.cc, decade, bb.dec, bb.yr, bb.space, LAT, LON, ALT)
bb.qr<-bb.qr[!duplicated(bb.qr),]
d<-full_join(bb.aes, bb.ag)
d<-full_join(d, bb.bp)
d<-full_join(d, bb.fsyl)
d<-full_join(d, bb.fex)
d<-full_join(d, bb.qr)
#dxx<-inner_join(dxx, d)
write.csv(d, file="~/Documents/git/regionalrisk/analyses/output/fs_bb_sitedata.csv", row.names = FALSE)
#prep_bb$lat<-round(prep_bb$lat, digits=0)
#prep_bb$long<-round(prep_bb$long, digits=0)
bb.mod<-brm(fs~year+bb.yr+(1|species), data=d, family=bernoulli)
View(d)
